{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jibin\\AppData\\Local\\Temp\\ipykernel_24188\\2776266437.py:13: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[\"bmi\"].fillna(imputation_values['bmi'], inplace=True)\n",
      "C:\\Users\\jibin\\AppData\\Local\\Temp\\ipykernel_24188\\2776266437.py:14: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[\"avg_glucose_level\"].fillna(imputation_values['avg_glucose_level'], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"healthcare-dataset-stroke-data.csv\")\n",
    "\n",
    "# Store and save imputation values\n",
    "imputation_values = {\n",
    "    'bmi': df['bmi'].median(),\n",
    "    'avg_glucose_level': df['avg_glucose_level'].median(),\n",
    "    'hypertension': df['hypertension'].mode()[0],\n",
    "    'heart_disease': df['heart_disease'].mode()[0]\n",
    "}\n",
    "joblib.dump(imputation_values, 'imputation_values.pkl')\n",
    "\n",
    "# Handle missing values\n",
    "df[\"bmi\"].fillna(imputation_values['bmi'], inplace=True)\n",
    "df[\"avg_glucose_level\"].fillna(imputation_values['avg_glucose_level'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['encoders.pkl']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = LabelEncoder()\n",
    "columns_to_encode = ['gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status']\n",
    "encoders = {}  # Store encoders for production use\n",
    "\n",
    "for col in columns_to_encode:\n",
    "    encoders[col] = LabelEncoder()\n",
    "    df[col] = encoders[col].fit_transform(df[col])\n",
    "\n",
    "# Save encoders for production\n",
    "joblib.dump(encoders, 'encoders.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and target\n",
    "X = df.drop(['stroke', 'id'], axis=1)\n",
    "y = df['stroke']\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Save scaler for production\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize models\n",
    "logreg = LogisticRegression(max_iter=1000, random_state=42)\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "gb = GradientBoostingClassifier(random_state=42)\n",
    "svc = SVC(probability=True, random_state=42)\n",
    "knn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.9393\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['stroke_model.pkl']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('logreg', logreg), ('rf', rf), ('gb', gb), ('svc', svc), ('knn', knn)],\n",
    "    voting='soft'\n",
    ")\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate model\n",
    "accuracy = voting_clf.score(X_test, y_test)\n",
    "print(f'Model Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Save final model\n",
    "joblib.dump(voting_clf, 'stroke_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
